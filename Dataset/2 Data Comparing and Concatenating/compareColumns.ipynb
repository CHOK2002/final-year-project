{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify Column names between 3 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names of 'News_Articles_1':\n",
      "['Index', 'Author', 'Date published', 'Category', 'Section', 'Url', 'Headline', 'Description', 'Keywords', 'Second headline', 'Article text']\n",
      "\n",
      "Column names of 'News_Articles_2':\n",
      "['Index', 'Author', 'Date published', 'Category', 'Section', 'Url', 'Headline', 'Description', 'Keywords', 'Second headline', 'Article text']\n",
      "\n",
      "Column names of 'News_Articles_3':\n",
      "['Unnamed: 0', 'Title', 'Description', 'Body', 'Keywords', 'Theme', 'Link']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the datasets\n",
    "news_articles_1 = pd.read_csv(\"News_Articles_1.csv\")\n",
    "news_articles_2 = pd.read_csv(\"News_Articles_2.csv\")\n",
    "news_articles_3 = pd.read_csv(\"News_Articles_3.csv\")\n",
    "\n",
    "# show column names for each dataset\n",
    "print(\"Column names of 'News_Articles_1':\")\n",
    "print(news_articles_1.columns.tolist())\n",
    "\n",
    "print(\"\\nColumn names of 'News_Articles_2':\")\n",
    "print(news_articles_2.columns.tolist())\n",
    "\n",
    "print(\"\\nColumn names of 'News_Articles_3':\")\n",
    "print(news_articles_3.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show Top 3 data in News_Artcles_1 (Possible same columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 data from 'News_Articles_1' dataset:\n",
      "                                            Headline  \\\n",
      "0  There's a shortage of truckers, but TuSimple t...   \n",
      "1  Bioservo's robotic 'Ironhand' could protect fa...   \n",
      "2  This swarm of robots gets smarter the more it ...   \n",
      "\n",
      "                                         Description  \\\n",
      "0  The e-commerce boom has exacerbated a global t...   \n",
      "1  Working in a factory can mean doing the same t...   \n",
      "2  In a Hong Kong warehouse, a swarm of autonomou...   \n",
      "\n",
      "                                        Article text  \\\n",
      "0   (CNN)Right now, there's a shortage of truck d...   \n",
      "1   (CNN)Working in a factory or warehouse can me...   \n",
      "2   (CNN)In a Hong Kong warehouse, a swarm of aut...   \n",
      "\n",
      "                                            Keywords Category  \\\n",
      "0  world, There's a shortage of truckers, but TuS...     news   \n",
      "1  world, Bioservo's robotic 'Ironhand' could pro...     news   \n",
      "2  asia, This swarm of robots gets smarter the mo...     news   \n",
      "\n",
      "                                                 Url  \n",
      "0  https://www.cnn.com/2021/07/14/world/tusimple-...  \n",
      "1  https://www.cnn.com/2021/05/12/world/ironhand-...  \n",
      "2  https://www.cnn.com/2021/06/15/asia/swarm-robo...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the dataset\n",
    "news_articles_1 = pd.read_csv(\"News_Articles_1.csv\")\n",
    "\n",
    "# selecting specific columns and displaying the top 5 rows\n",
    "print(\"Top 3 data from 'News_Articles_1' dataset:\")\n",
    "print(news_articles_1[['Headline', 'Description', 'Article text', 'Keywords', 'Category', 'Url']].head(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show Top 3 data in News_Artcles_3 (Possible same columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 data from 'News_Articles_3' dataset:\n",
      "                                               Title  \\\n",
      "0  Candy factory didn't evacuate concerned worker...   \n",
      "1  Baltimore police ask for public's help identif...   \n",
      "2  An arrest warrant has been issued for a suspec...   \n",
      "\n",
      "                                         Description  \\\n",
      "0  An eastern Pennsylvania candy factory didn’t e...   \n",
      "1  Two shooters were involved in an attack at Mor...   \n",
      "2  Authorities in Pennsylvania say they have issu...   \n",
      "\n",
      "                                                Body  \\\n",
      "0  An eastern Pennsylvania candy factory didn’t e...   \n",
      "1  Two shooters were involved in an attack at Mor...   \n",
      "2  Authorities in Pennsylvania say they have issu...   \n",
      "\n",
      "                                            Keywords Theme  \\\n",
      "0  accident investigations, accidents, accidents,...    us   \n",
      "1  baltimore, brand safety-nsf crime, brand safet...    us   \n",
      "2  arrest warrants, arrests, brand safety-nsf cri...    us   \n",
      "\n",
      "                                                Link  \n",
      "0  https://edition.cnn.com/2023/10/06/us/pennsylv...  \n",
      "1  https://edition.cnn.com/2023/10/06/us/morgan-s...  \n",
      "2  https://edition.cnn.com/2023/10/06/us/josh-kru...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the dataset\n",
    "news_articles_3 = pd.read_csv(\"News_Articles_3.csv\")\n",
    "\n",
    "# selecting specific columns and displaying the top 5 rows\n",
    "print(\"Top 3 data from 'News_Articles_3' dataset:\")\n",
    "print(news_articles_3[['Title', 'Description', 'Body', 'Keywords', 'Theme', 'Link']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renamed columns in the News_Articles_3 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the CSV file\n",
    "df = pd.read_csv('News_Articles_3.csv')\n",
    "\n",
    "# rename the columns\n",
    "df_renamed = df.rename(columns={\n",
    "    'Title': 'Headline',\n",
    "    'Body': 'Article text',\n",
    "    'Theme': 'Category',\n",
    "    'Link': 'Url'\n",
    "})\n",
    "\n",
    "# save the updated DataFrame back to a new CSV file\n",
    "df_renamed.to_csv('News_Articles_3.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
