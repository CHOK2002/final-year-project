{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Means Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# load dataset\n",
    "df = pd.read_csv('Cleaned_News_Articles_Final.csv')\n",
    "df = df[['headline']]\n",
    "\n",
    "headlines = df['headline'].tolist()\n",
    "\n",
    "# TF-IDF Vetorizer\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X = vectorizer.fit_transform(headlines)\n",
    "\n",
    "# kmeans clustering\n",
    "num_clusters = 3  # nega posi neutral\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# assign sentiment labels to clusters\n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "cluster_labels = kmeans.labels_\n",
    "\n",
    "# clusters and their labels\n",
    "df['cluster_label'] = kmeans.labels_\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['sentiment'] = label_encoder.fit_transform(df['cluster_label'])\n",
    "\n",
    "# print(df[['headline', 'sentiment']])\n",
    "\n",
    "# decode back to negative, positive, neutral\n",
    "inverse_mapping = {0: 'negative', 1: 'positive', 2: 'neutral'}\n",
    "df['sentiment'] = df['sentiment'].map(inverse_mapping)\n",
    "\n",
    "df.drop(columns=['cluster_label'], inplace=True)\n",
    "\n",
    "# print(df[['headline', 'sentiment']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('kmeans_without_augmented.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# reduce dimensionality using PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X.toarray())\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=df['sentiment'], palette='Set1', legend='full')\n",
    "plt.title('PCA Visualization of Clusters')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Silhouette Score Before Augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "clusters = kmeans.fit_predict(X_pca)\n",
    "\n",
    "silhouette_avg = silhouette_score(X_pca, clusters)\n",
    "db_index = davies_bouldin_score(X_pca, clusters)\n",
    "\n",
    "print(f'Silhouette Score: {silhouette_avg}')\n",
    "print(f'Davies-Bouldin Index: {db_index}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmented Data with 4 Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the data \n",
    "file_path = \"kmeans_without_augmented.csv\"\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nlpaug.augmenter.word as naw\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import os\n",
    "import nltk\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# load dataset\n",
    "file_path = 'kmeans_without_augmented.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# minority sentiment\n",
    "minority_labels = {\n",
    "    \"neutral\": 2546,\n",
    "    \"positive\": 2057,\n",
    "}\n",
    "\n",
    "# technique to augmented\n",
    "aug = naw.ContextualWordEmbsAug(\n",
    "    model_path='distilbert-base-uncased', action=\"substitute\")\n",
    "\n",
    "aug2 = naw.ContextualWordEmbsAug(\n",
    "    model_path='roberta-base', action=\"substitute\")\n",
    "\n",
    "aug_insert = naw.ContextualWordEmbsAug(\n",
    "    model_path='roberta-base', action=\"insert\")\n",
    "\n",
    "aug_synonym = naw.SynonymAug(aug_src='wordnet')\n",
    "\n",
    "# lists to store augmented data\n",
    "augmented_summaries = []\n",
    "multilabels = []\n",
    "\n",
    "for _, row in tqdm(data.iterrows(), total=len(data)):\n",
    "    if isinstance(row['sentiment'], str):\n",
    "        augmented_labels = row['sentiment'].split(',') \n",
    "        augmented_labels_filtered = [label.strip() for label in augmented_labels if label.strip() in minority_labels]\n",
    "        \n",
    "        if augmented_labels_filtered:\n",
    "            # augment the summary for in headline\n",
    "            augmented_summary = aug.augment(row['headline'])\n",
    "            augmented_summary2 = aug2.augment(row['headline'])\n",
    "            augmented_summary_insert = aug_insert.augment(row['headline'])\n",
    "            augmented_summary_synonym = aug_synonym.augment(row['headline'])\n",
    "            \n",
    "            # append to the lists\n",
    "            augmented_summaries.extend([augmented_summary, augmented_summary2, augmented_summary_insert, augmented_summary_synonym])\n",
    "            multilabels.extend([row['sentiment']] * 4)\n",
    "\n",
    "augmented_df = pd.DataFrame({'headline': augmented_summaries, 'sentiment': multilabels})\n",
    "\n",
    "data_augmented_path = 'kmeans_with_augmented.csv'\n",
    "augmented_df.to_csv(data_augmented_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check total of augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmented_path = \"kmeans_with_augmented.csv\"\n",
    "augmented_df = pd.read_csv(data_augmented_path)\n",
    "augmented_df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine Augmented data & without Augmented Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# combine data\n",
    "csv_files = ['kmeans_with_augmented.csv', 'kmeans_without_augmented.csv']\n",
    "\n",
    "# initialize an empty list\n",
    "dfs = []\n",
    "\n",
    "# append its data to the list\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "combined_data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# sort the combined data in sentiment column\n",
    "sorted2_data = combined_data.sort_values(by='sentiment')\n",
    "\n",
    "final_aug_path = \"final_kmeans.csv\"\n",
    "sorted2_data.to_csv(final_aug_path, index=False)\n",
    "\n",
    "sorted2_data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove square brackets, single quotes, and double quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_file = 'final_kmeans.csv'\n",
    "output_file = 'final_kmeans.csv'\n",
    "\n",
    "# load dataset\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# remove square brackets, single quotes, double quotes\n",
    "df['headline'] = df['headline'].str.replace(r\"[\\[\\]\\\"']\", '', regex=True)\n",
    "\n",
    "df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downsampling to select each sentiment 10000 data (Balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load dataset\n",
    "df = pd.read_csv('final_kmeans.csv')  \n",
    "\n",
    "# select 10000 data for each sentiment\n",
    "lower_limit = 100\n",
    "upper_limit = 10000\n",
    "\n",
    "# grp the data by sentiment and perform downsampling within each grp\n",
    "downsampled_data = df.groupby('sentiment').apply(lambda x: x.sample(n=min(upper_limit, max(lower_limit, len(x))), random_state=42))\n",
    "\n",
    "downsampled_data = downsampled_data.reset_index(drop=True)\n",
    "\n",
    "downsampled_data.to_csv('final_kmeans_subset.csv', index=False)  # The 'index=False' parameter is used to not write row indices\n",
    "\n",
    "downsampled_data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Silhouette Score After Augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# load dataset\n",
    "df = pd.read_csv('final_kmeans_subset.csv')  \n",
    "\n",
    "# encode sentiment labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['sentiment_label'] = label_encoder.fit_transform(df['sentiment'])\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(df['headline'])\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "clusters = kmeans.fit_predict(X)\n",
    "\n",
    "silhouette_avg = silhouette_score(X, clusters)\n",
    "print(f'Silhouette Score: {silhouette_avg}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# load the dataset\n",
    "dataset_path = 'final_kmeans_subset.csv'    #can CHANGE\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# split into training and testing sets (70 30)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['headline'], df['sentiment'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode and Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # encode labels (negative=0 positive=1 neutral=2)\n",
    "y_train = y_train.map({'negative': 0, 'positive': 1, 'neutral': 2})\n",
    "y_test = y_test.map({'negative': 0, 'positive': 1, 'neutral': 2})\n",
    "\n",
    "# TF-IDF vector\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train  ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# ML baseline model (select 1 to run)    #can CHANGE\n",
    "# ml_models = LogisticRegression()\n",
    "# ml_models = RandomForestClassifier()\n",
    "# ml_models = MultinomialNB()\n",
    "# ml_models = SVC()\n",
    "ml_models = KNeighborsClassifier()\n",
    "\n",
    "\n",
    "ml_models.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# convert model name to string\n",
    "model_name = ml_models.__class__.__name__\n",
    "\n",
    "# start MLflow\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"sentiment-analysis-kmeans\")\n",
    "\n",
    "# initialize MLflow client\n",
    "client = MlflowClient()\n",
    "\n",
    "# experiment ID\n",
    "experiment_id = client.get_experiment_by_name(\"sentiment-analysis-kmeans\").experiment_id\n",
    "\n",
    "runs = client.search_runs(experiment_ids=[experiment_id])\n",
    "\n",
    "# initial version to 0\n",
    "max_version = 0\n",
    "\n",
    "# find the max version for the current version model\n",
    "for run in runs:\n",
    "    run_name = run.data.tags.get('mlflow.runName')\n",
    "    if run_name and run_name.startswith(model_name):        \n",
    "        # extract version number from the run name\n",
    "        try:\n",
    "            version = int(run_name.split('_v')[-1])\n",
    "        except ValueError:\n",
    "            continue  # skip if version is not an integer\n",
    "\n",
    "        # update max_version if this version is greater\n",
    "        max_version = max(max_version, version)\n",
    "\n",
    "# increase the version by adding 1\n",
    "new_version = max_version + 1\n",
    "\n",
    "# new run name\n",
    "new_run_name = f\"{model_name}_v{new_version}\"\n",
    "mlflow.start_run(run_name=new_run_name)\n",
    "\n",
    "mlflow.log_param(\"model name\", model_name)\n",
    "mlflow.log_param(\"dataset_name\", dataset_path)\n",
    "mlflow.log_param(\"data size\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict Accuracy (Based Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# predict test \n",
    "y_pred = ml_models.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Based Model:\")\n",
    "\n",
    "#  training accuracy\n",
    "trainAccuracy = ml_models.score(X_train_tfidf, y_train)\n",
    "print(\"Training Accuracy:\", trainAccuracy)\n",
    "\n",
    "# training loss (MISC)\n",
    "training_loss = ml_models.score(X_train_tfidf, y_train)\n",
    "print(\"Training Loss (MISC):\", 1 - training_loss)\n",
    "\n",
    "# test accuracy\n",
    "testAccuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Testing Accuracy:\", testAccuracy)\n",
    "\n",
    "# precison recall f1score\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix (Based Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# decode the labels back to original\n",
    "reverse_mapping = {0: 'negative', 1: 'positive', 2: 'neutral'}\n",
    "decoded_y_pred = [reverse_mapping[label] for label in y_pred]\n",
    "decoded_y_test = [reverse_mapping[label] for label in y_test]\n",
    "\n",
    "# create confusion matrix\n",
    "conf_matrix = confusion_matrix(decoded_y_test, decoded_y_pred)\n",
    "\n",
    "# plot confusion matrix \n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='d', cbar=False)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xticks(ticks=[0.5, 1.5, 2.5], labels=['negative', 'positive', 'neutral'])\n",
    "plt.yticks(ticks=[0.5, 1.5, 2.5], labels=['negative', 'positive', 'neutral'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC Curve (Based Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# binarize the labels\n",
    "y_test_binarized = label_binarize(y_test, classes=[0, 1, 2])\n",
    "\n",
    "# proba for proba models , decision for svm\n",
    "y_pred_scores = ml_models.predict_proba(X_test_tfidf)       #can CHANGE\n",
    "# y_pred_scores = ml_models.decision_function(X_test_tfidf)   \n",
    "\n",
    "# compute and plot ROC curve\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "n_classes = y_test_binarized.shape[1]\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], y_pred_scores[:, i])\n",
    "    roc_auc[i] = roc_auc_score(y_test_binarized[:, i], y_pred_scores[:, i])\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "colors = ['blue', 'red', 'green']\n",
    "classes = ['negative', 'positive', 'neutral']\n",
    "for i, color in enumerate(colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2, \n",
    "             label=f'ROC curve for {classes[i]} (area = {roc_auc[i]:0.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve for Multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# ML models classifier                 #can CHANGE\n",
    "# ml_models = LogisticRegression()  \n",
    "# ml_models = RandomForestClassifier()\n",
    "# ml_models = MultinomialNB()\n",
    "# ml_models = SVC()\n",
    "ml_models = KNeighborsClassifier()\n",
    "\n",
    "\n",
    "# hyperparameters to tune    #can CHANGE\n",
    "\n",
    "#LR\n",
    "# param_grid = {\n",
    "#     'C': [0.1, 1.0, 10.0],\n",
    "#     'penalty': ['l1', 'l2'],\n",
    "#     'solver': ['liblinear', 'saga']\n",
    "# }\n",
    "\n",
    "# #RF\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200],\n",
    "#     'max_features': ['auto', 'sqrt'],\n",
    "#     'max_depth': [10, 20],\n",
    "#     'min_samples_split': [2, 5],\n",
    "#     'min_samples_leaf': [1, 2],\n",
    "#     'bootstrap': [True]\n",
    "# }\n",
    "\n",
    "# #MNB\n",
    "# param_grid = {\n",
    "#     'alpha': [0.1, 0.5, 1.0],\n",
    "#     'fit_prior': [True, False]\n",
    "# }\n",
    "\n",
    "# #SVM\n",
    "# param_grid = {\n",
    "#     'C': [1, 5],\n",
    "#     'kernel': ['linear', 'poly'],\n",
    "#     'gamma': ['scale', 'auto']\n",
    "# }\n",
    "\n",
    "# KNN\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "\n",
    "\n",
    "# perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=ml_models, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# fit the grid search to the data\n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# best hyperparameters and corresponding score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Cross-Validation Accuracy:\", best_score)\n",
    "\n",
    "# make predictions\n",
    "best_model = grid_search.best_estimator_\n",
    "predictions_test = best_model.predict(X_test_tfidf)\n",
    "\n",
    "# calculate accuracy \n",
    "best_model_train_score = best_model.score(X_train_tfidf, y_train)\n",
    "best_model_test_score = best_model.score(X_test_tfidf, y_test)\n",
    "\n",
    "print()\n",
    "print(\"Best Model:\")\n",
    "print(\"Training Score: {}\\nTest Score: {}\".format(best_model_train_score, best_model_test_score))\n",
    "\n",
    "# classification report\n",
    "report = classification_report(y_test, predictions_test, output_dict=True)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, predictions_test))\n",
    "\n",
    "mlflow.log_param(\"best params\", best_params)\n",
    "\n",
    "mlflow.log_metric(\"train accuracy\", best_model_train_score)\n",
    "mlflow.log_metric(\"test accuracy\", best_model_test_score)\n",
    "\n",
    "mlflow.log_metric(\"Precision\", report['weighted avg']['precision'])\n",
    "mlflow.log_metric(\"Recall\", report['weighted avg']['recall'])\n",
    "mlflow.log_metric(\"F1 Score\", report['weighted avg']['f1-score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix (Best Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# decode the labels back to original\n",
    "reverse_mapping = {0: 'negative', 1: 'positive', 2: 'neutral'}\n",
    "decoded_y_pred = [reverse_mapping[label] for label in predictions_test]\n",
    "decoded_y_test = [reverse_mapping[label] for label in y_test]\n",
    "\n",
    "# create confusion matrix\n",
    "conf_matrix = confusion_matrix(decoded_y_test, decoded_y_pred)\n",
    "\n",
    "# plot confusion matrix \n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='d', cbar=False)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xticks(ticks=[0.5, 1.5, 2.5], labels=['negative', 'positive', 'neutral'])\n",
    "plt.yticks(ticks=[0.5, 1.5, 2.5], labels=['negative', 'positive', 'neutral'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC Curve (Best Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# binarize the labels\n",
    "y_test_binarized = label_binarize(y_test, classes=[0, 1, 2])\n",
    "\n",
    "\n",
    "# proba for proba models , decision for svm\n",
    "y_pred_scores = best_model.predict_proba(X_test_tfidf)        #can CHANGE\n",
    "# y_pred_scores = best_model.decision_function(X_test_tfidf)\n",
    "\n",
    "# compute and plot ROC curve\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "n_classes = y_test_binarized.shape[1]\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], y_pred_scores[:, i])\n",
    "    roc_auc[i] = roc_auc_score(y_test_binarized[:, i], y_pred_scores[:, i])\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "colors = ['blue', 'red', 'green']\n",
    "classes = ['negative', 'positive', 'neutral']\n",
    "for i, color in enumerate(colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2, \n",
    "             label=f'ROC curve for {classes[i]} (area = {roc_auc[i]:0.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve for Multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "# create subfolders\n",
    "base_folder = '5 Unsupervised Sentiment Analysis/kmeans_models_fextract'\n",
    "models_folder = os.path.join(base_folder, 'models')\n",
    "feature_extract_folder = os.path.join(base_folder, 'feature_extract')\n",
    "\n",
    "# double confirm \n",
    "os.makedirs(models_folder, exist_ok=True)\n",
    "os.makedirs(feature_extract_folder, exist_ok=True)\n",
    "\n",
    "# save best model and TFIDF vectorizer \n",
    "joblib.dump(best_model, os.path.join(models_folder, 'best_knn_model_kmeans.pkl'))    #CHANGE model name and dataset name\n",
    "print('Best model saved')\n",
    "\n",
    "joblib.dump(tfidf_vectorizer, os.path.join(feature_extract_folder, 'knn_tfidf_kmeans.pkl'))    #CHANGE also\n",
    "print('TFIDF saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# load the saved model and tfidf vectorizer\n",
    "model_filename = '5 Unsupervised Sentiment Analysis/kmeans_models_fextract/models/best_knn_model_kmeans.pkl'\n",
    "vectorizer_filename = '5 Unsupervised Sentiment Analysis/kmeans_models_fextract/feature_extract/knn_tfidf_kmeans.pkl'\n",
    "\n",
    "model = joblib.load(model_filename)\n",
    "vectorizer = joblib.load(vectorizer_filename)\n",
    "\n",
    "# encode the label\n",
    "label_encoding = {0: 'negative', 1: 'positive', 2: 'neutral'}\n",
    "\n",
    "\n",
    "# unseen data\n",
    "# input_text = \"McDonald’s shortens breakfast time in Australia as bird flu causes egg shortage\"\n",
    "# input_text = \"Tesla sales fall again as more automakers crowd electric vehicle market\"\n",
    "input_text = \"today is a bad day\"\n",
    "# input_text = \"Global Summit Yields New Climate Accord\"\n",
    "# input_text = 'Local Communities Rally for Better Infrastructure'\n",
    "\n",
    "# vector the unseen data\n",
    "transformed_input = vectorizer.transform([input_text])\n",
    "\n",
    "# predit the unseen data by usig saved model\n",
    "prediction = model.predict(transformed_input)\n",
    "\n",
    "# decode the label into its original class\n",
    "decoded_prediction = label_encoding[prediction[0]]\n",
    "\n",
    "# print result\n",
    "print(f\"Prediction: {decoded_prediction}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
