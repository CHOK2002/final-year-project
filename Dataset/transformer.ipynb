{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load pretrained model from huggingface\n",
    "model_name = 'shashanksrinath/News_Sentiment_Analysis'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name) #from_tf=True\n",
    "\n",
    "# use gpu if no then default cpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "data = pd.read_csv('Cleaned_News_Articles_Final2.csv')\n",
    "data = data[['headline']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41795/41795 [00:20<00:00, 1997.31it/s]\n",
      "100%|██████████| 41795/41795 [47:19<00:00, 14.72it/s] \n"
     ]
    }
   ],
   "source": [
    "def preprocess(text):\n",
    "    inputs = tokenizer.encode_plus(text, truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}  # Move inputs to CPU\n",
    "    return inputs\n",
    "\n",
    "# sentiment function\n",
    "def get_sentiment(inputs):\n",
    "    outputs = model(**inputs)\n",
    "    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    sentiment = torch.argmax(probs)\n",
    "    return sentiment.item(), probs.tolist()[0]\n",
    "\n",
    "# apply tqdm to track progress \n",
    "tqdm.pandas()  \n",
    "data['inputs'] = data['headline'].progress_apply(preprocess)\n",
    "data['sentiment'], data['probs'] = zip(*data['inputs'].progress_apply(get_sentiment))\n",
    "\n",
    "# mapping sentiment to labels\n",
    "sentiment_dict = {0: 'negative', 1: 'positive', 2: 'neutral'}\n",
    "data['sentiment'] = data['sentiment'].map(sentiment_dict)\n",
    "\n",
    "# split the probabilities into nega posi neutral\n",
    "data[['prob_negative', 'prob_positive', 'prob_neutral']] = pd.DataFrame(data['probs'].tolist(), index=data.index)\n",
    "# data = data.drop(columns=['probs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('Pretrained_Predicited_Sentiment.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive    34076\n",
      "negative     6870\n",
      "neutral       849\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n",
      "Tokenizer saved\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "# create subfolders\n",
    "base_folder = '5 Unsupervised Sentiment Analysis/transformer'\n",
    "models_folder = os.path.join(base_folder, 'models')\n",
    "tokenizer_folder = os.path.join(base_folder, 'tokenizer')\n",
    "\n",
    "# double confirm \n",
    "os.makedirs(models_folder, exist_ok=True)\n",
    "os.makedirs(tokenizer_folder, exist_ok=True)\n",
    "\n",
    "# save model and tokenizer \n",
    "joblib.dump(model, os.path.join(models_folder, 'shashanksrinath_News_Sentiment_Analysis.pkl'))    #CHANGE model name and dataset name\n",
    "print('Model saved')\n",
    "\n",
    "joblib.dump(tokenizer, os.path.join(tokenizer_folder, 'shashanksrinath_News_Sentiment_Analysis.pkl'))    #CHANGE also\n",
    "print('Tokenizer saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RobertaTokenizerFast' object has no attribute 'transform'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m input_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesla sales fall again as more automakers crowd electric vehicle market\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# vector the unseen data\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m transformed_input \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mtransform([input_text])\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# predit the unseen data by usig saved model\u001b[39;00m\n\u001b[0;32m     21\u001b[0m prediction \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(transformed_input)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RobertaTokenizerFast' object has no attribute 'transform'"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# load the saved model and tokenizer\n",
    "model_filename = '5 Unsupervised Sentiment Analysis/transformer/models/shashanksrinath_News_Sentiment_Analysis.pkl'\n",
    "tokenizer_filename = '5 Unsupervised Sentiment Analysis/transformer/tokenizer/shashanksrinath_News_Sentiment_Analysis.pkl'\n",
    "\n",
    "model = joblib.load(model_filename)\n",
    "tokenizer = joblib.load(tokenizer_filename)\n",
    "\n",
    "# encode the label\n",
    "label_encoding = {0: 'negative', 1: 'positive', 2: 'neutral'}\n",
    "\n",
    "# unseen data\n",
    "# input_text = \"McDonald’s shortens breakfast time in Australia as bird flu causes egg shortage\"\n",
    "input_text = \"Tesla sales fall again as more automakers crowd electric vehicle market\"\n",
    "\n",
    "# vector the unseen data\n",
    "transformed_input = tokenizer.transform([input_text])\n",
    "\n",
    "# predit the unseen data by usig saved model\n",
    "prediction = model.predict(transformed_input)\n",
    "\n",
    "# decode the label into its original class\n",
    "decoded_prediction = label_encoding[prediction[0]]\n",
    "\n",
    "# print result\n",
    "print(f\"Prediction: {decoded_prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted sentiment: neutral\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Define paths for saving and loading\n",
    "base_folder = '5 Unsupervised Sentiment Analysis/transformer'\n",
    "models_folder = os.path.join(base_folder, 'modelss')\n",
    "tokenizer_folder = os.path.join(base_folder, 'tokenizers')\n",
    "\n",
    "# Create subfolders if they don't exist\n",
    "os.makedirs(models_folder, exist_ok=True)\n",
    "os.makedirs(tokenizer_folder, exist_ok=True)\n",
    "\n",
    "# Model and tokenizer names\n",
    "model_name = 'shashanksrinath/News_Sentiment_Analysis'\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Save tokenizer and model\n",
    "tokenizer.save_pretrained(tokenizer_folder)\n",
    "model.save_pretrained(models_folder)\n",
    "\n",
    "# Load tokenizer and model from the saved paths\n",
    "loaded_tokenizer = AutoTokenizer.from_pretrained(tokenizer_folder)\n",
    "loaded_model = AutoModelForSequenceClassification.from_pretrained(models_folder)\n",
    "\n",
    "# Example of using loaded tokenizer and model on new data\n",
    "text = \"Your new headline text here.\"\n",
    "inputs = loaded_tokenizer.encode_plus(text, truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
    "outputs = loaded_model(**inputs)\n",
    "probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "sentiment = torch.argmax(probs)\n",
    "sentiment_label = {0: 'negative', 1: 'neutral', 2: 'positive'}[sentiment.item()]\n",
    "\n",
    "print(f\"Predicted sentiment: {sentiment_label}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
