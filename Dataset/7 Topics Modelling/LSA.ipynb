{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic Modelling by using LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load dataset\n",
    "dataset_path = 'balanced_category.csv'\n",
    "df = pd.read_csv(dataset_path)\n",
    "# df = df[['text','category']]\n",
    "\n",
    "print(df['category'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extraction (TF-IDF and BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use tfidf vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_doc_term_matrix = tfidf_vectorizer.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_doc_term_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use bow vectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bow_vectorizer = CountVectorizer()\n",
    "bow_doc_term_matrix = bow_vectorizer.fit_transform(df['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_doc_term_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# LSA model\n",
    "n_topics = 10\n",
    "lsa = TruncatedSVD(n_components=n_topics, random_state=42, algorithm='randomized')\n",
    "\n",
    "# fit the LSA model to the matrix\n",
    "lsa.fit(bow_doc_term_matrix)\n",
    "tsvd_mat = lsa.transform(bow_doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply t-SNE for LSA transformation\n",
    "tsne_lsa = TSNE(n_components=2, random_state=42)\n",
    "tsne_lsa_mat = tsne_lsa.fit_transform(tsvd_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define a custom bright color palette\n",
    "bright_palette = sns.color_palette([\"#FF6347\", \"#4682B4\", \"#32CD32\", \"#FFD700\", \"#FF69B4\"])\n",
    "\n",
    "# Visualize LSA topics using t-SNE with custom bright colors\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(x=tsne_lsa_mat[:, 0], y=tsne_lsa_mat[:, 1], hue=df['category'], palette=bright_palette)\n",
    "plt.title('t-SNE visualization of LSA topics')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLflow Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# convert model name to string\n",
    "model_name = lsa.__class__.__name__\n",
    "vectorizeer_name = bow_vectorizer.__class__.__name__   #can CHANGE\n",
    "\n",
    "# start MLflow\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"topic-modelling\")\n",
    "\n",
    "# initialize MLflow client\n",
    "client = MlflowClient()\n",
    "\n",
    "# experiment ID\n",
    "experiment_id = client.get_experiment_by_name(\"topic-modelling\").experiment_id\n",
    "\n",
    "runs = client.search_runs(experiment_ids=[experiment_id])\n",
    "\n",
    "# initial version to 0\n",
    "max_version = 0\n",
    "\n",
    "# find the max version for the current version model\n",
    "for run in runs:\n",
    "    run_name = run.data.tags.get('mlflow.runName')\n",
    "    if run_name and run_name.startswith(model_name):        \n",
    "        # extract version number from the run name\n",
    "        try:\n",
    "            version = int(run_name.split('_v')[-1])\n",
    "        except ValueError:\n",
    "            continue  # skip if version is not an integer\n",
    "\n",
    "        # update max_version if this version is greater\n",
    "        max_version = max(max_version, version)\n",
    "\n",
    "# increase the version by adding 1\n",
    "new_version = max_version + 1\n",
    "\n",
    "# new run name\n",
    "new_run_name = f\"{model_name}_v{new_version}\"\n",
    "mlflow.start_run(run_name=new_run_name)\n",
    "\n",
    "mlflow.log_param(\"model name\", model_name)\n",
    "mlflow.log_param(\"vectorizer name\", vectorizeer_name)\n",
    "mlflow.log_param(\"dataset_name\", dataset_path)\n",
    "mlflow.log_param(\"data size\", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Cloud for 10 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "feature_names = bow_vectorizer.get_feature_names_out()   # can CHANGE\n",
    "\n",
    "for i, topic in enumerate(lsa.components_):\n",
    "    plt.figure()\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').fit_words(dict(zip(feature_names, topic)))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Topic {i+1}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic Words Score visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# colors for each topic\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, 10))\n",
    "\n",
    "# subplots\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6), sharex=False, sharey=False)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (topic, color) in enumerate(zip(lsa.components_, colors)):\n",
    "    top_words_idx = np.argsort(topic)[::-1][:10]  # descending order\n",
    "    top_words = feature_names[top_words_idx]\n",
    "    top_scores = topic[top_words_idx]\n",
    "\n",
    "    ax = axes[i]\n",
    "    ax.barh(top_words, top_scores, color=color)\n",
    "    ax.set_title(f'Topic {i}', fontsize=12, fontweight='bold')\n",
    "    ax.invert_yaxis()\n",
    "    ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "fig.suptitle('Top Words per Topic', fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Gensim to calculate the Coherence Scores and Visualize Intertopic Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "# create dic, corpus and tokenized\n",
    "tokenized_docs = [doc.split() for doc in df['text']]\n",
    "dictionary = Dictionary(tokenized_docs)\n",
    "corpus = [dictionary.doc2bow(text) for text in tokenized_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize in intertopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.ldamodel import LdaModel\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis\n",
    "\n",
    "# pyLDAvis\n",
    "lda_gensim = LdaModel(corpus=corpus, id2word=dictionary, num_topics=n_topics)\n",
    "vis_data = gensimvis.prepare(lda_gensim, corpus, dictionary)\n",
    "pyLDAvis.display(vis_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate by Coherence Scores with c_v and u_mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "topics = lsa.components_\n",
    "\n",
    "# convert topics to words\n",
    "top_words_per_topic = []\n",
    "for topic in topics:\n",
    "    top_words_idx = topic.argsort()[-10:]  # Get indices of the top words for this topic\n",
    "    top_words = [feature_names[i] for i in top_words_idx]\n",
    "    top_words_per_topic.append(top_words)\n",
    "\n",
    "# C_V coherence score\n",
    "cv_coherence_model = CoherenceModel(topics=top_words_per_topic, texts=tokenized_docs, dictionary=dictionary, coherence='c_v')\n",
    "cv_coherence = cv_coherence_model.get_coherence()\n",
    "\n",
    "# U_Mass coherence score\n",
    "umass_coherence_model = CoherenceModel(topics=top_words_per_topic, corpus=corpus, dictionary=dictionary, coherence='u_mass')\n",
    "umass_coherence = umass_coherence_model.get_coherence()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(range(n_topics), cv_coherence_model.get_coherence_per_topic(), marker='o', label='C_V Coherence')\n",
    "\n",
    "plt.plot(range(n_topics), umass_coherence_model.get_coherence_per_topic(), marker='o', label='U_Mass Coherence')\n",
    "\n",
    "plt.xlabel('Topic')\n",
    "plt.ylabel('Coherence Score')\n",
    "plt.title('Coherence Scores per Topic')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Overall C_V Coherence Score: {cv_coherence}\")\n",
    "print(f\"Overall U_Mass Coherence Score: {umass_coherence}\")\n",
    "\n",
    "mlflow.log_metric(\"c_v coherence\", cv_coherence)\n",
    "mlflow.log_metric(\"u_mass coherence\", umass_coherence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(n_topics), cv_coherence_model.get_coherence_per_topic())\n",
    "plt.xlabel('Topic')\n",
    "plt.ylabel('C_V Coherence Score')\n",
    "plt.title('C_V Coherence Scores per Topic')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(n_topics), umass_coherence_model.get_coherence_per_topic())\n",
    "plt.xlabel('Topic')\n",
    "plt.ylabel('U_Mass Coherence Score')\n",
    "plt.title('U_Mass Coherence Scores per Topic')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Overall C_V Coherence Score: {cv_coherence}\")\n",
    "print(f\"Overall U_Mass Coherence Score: {umass_coherence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(lsa, 'lsa_bow_with_balance.pkl')\n",
    "joblib.dump(bow_vectorizer, 'bow_vectorizer_with_balance.pkl')   #can CHANGE\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
